name: LLM Chatbot Augmented with Enterprise Data
description: |
  This AMP demonstrates how to use an open source pre-trained instruction-following LLM (Large Language Model) to build a ChatBot-like web application. The responses of the LLM are enhanced by giving it context from an internal knowledge base. This context is retrieved by using an open source Vector Database to do semantic search.

author: Cloudera Inc.
specification_version: 1.0
prototype_version: 1.0
date: "2023-04-22"

runtimes:
  - editor: Workbench
    kernel: Python 3.9
    edition: Nvidia GPU

tasks:
  - type: run_session
    name: Validate GPU Availibility
    script: 0_session-resource-validation/check_gpu_resources.py
    short_summary: Check for GPU availibility. 
    long_summary: Check GPUs are enabled on this workspace and are currently schedulable.
    kernel: python3
    cpu: 2
    memory: 4
  
  - type: run_session
    name: Validate GPU Capability
    script: 0_session-resource-validation/check_gpu_capability.py
    short_summary: Check for GPU capability. 
    long_summary: Check GPU device supports the CUDA capabilities required.
    kernel: python3
    cpu: 2
    memory: 4
    gpu: 1

  - type: run_session
    name: Install Dependencies
    script: 1_session-install-deps/install_dependencies.py
    short_summary: Install Dependencies
    kernel: python3
    cpu: 2
    memory: 8

  - type: create_job
    name: Download Models
    entity_label: download_data_and_models
    script: 2_job-download-models/download_models.py
    arguments: None
    short_summary: Create job to download pre-trained models. 
    long_summary: Create job to download open source pre-trained models required by the LLM Chatbot application. All models are downloaded to a local directory. 
    cpu: 1
    memory: 4
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: download_data_and_models
    short_summary: Run job to download pre-trained models.
    
  - type: create_job
    name: Populate Vector DB with documents embeddings
    entity_label: vectordb_insert
    script: 3_job-populate-vectordb/vectordb_insert.py
    arguments: None
    short_summary: Create job to populate Vector Database with document embeddings. 
    long_summary: Create job to launch Milvus Vector Database locally and insert embeddings for documents. Embeddings are generated by the locally running embeddings model.
    cpu: 1
    memory: 4
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: vectordb_insert
    short_summary: Populate Vector DB with documents embeddings
  
  - type: start_application
    name: CML LLM Chatbot
    subdomain: cmlllm
    script: 4_app/llm_rag_app.py
    short_summary: Start CML LLM Chatbot application
    long_summary: This application requires an available GPU to run the LLM model. Startup may be delayed if autoscaling is being performed or fail if GPU cannot be scheduled on this workspace. Please contact your administrator for GPU scheduling.
    cpu: 2
    memory: 16
    gpu: 1
    environment_variables:
      TASK_TYPE: START_APPLICATION
